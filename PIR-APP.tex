\documentclass[man, noextraspace, floatsintext]{apa6}\usepackage[]{graphicx}\usepackage[]{color}
%% maxwidth is the original width if it is less than linewidth
%% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}
\newcommand{\bibfile}{C:/Users/jep2963/Documents/Bibliography/Behavioral_observation-APP}  

\usepackage[natbibapa]{apacite}
\newcommand{\citetal}[1]{\shortcites{#1}\citet{#1}}

\raggedbottom

\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{graphicx}

\usepackage{fixltx2e}
\usepackage{subcaption}
\usepackage{float}

\usepackage{array}
\usepackage{multirow}
\usepackage{rotating}
\setlength{\rotFPtop}{0pt plus 1fil}
\usepackage[draft]{changes}

\geometry{twoside=false, top=1in, bottom=1in, left=1in, right=1.2in}
\usepackage[textwidth=1in, textsize=tiny]{todonotes}

\newcommand{\Prob}{\text{Pr}}
\newcommand{\E}{\text{E}}
\newcommand{\Cov}{\text{Cov}}
\newcommand{\corr}{\text{corr}}
\newcommand{\Var}{\text{Var}}
\newcommand{\iid}{\stackrel{\text{iid}}{\sim}}
\newcommand{\logit}{\text{logit}}
\newcommand{\cll}{\text{cll}}


\title{An Alternating Poisson Process model for estimating prevalence and incidence from interval recording data}
\shorttitle{ALTERNATING POISSON PROCESS FOR INTERVAL RECORDING DATA}
\author{James E. Pustejovsky and Daniel M. Swan}
\leftheader{Pustejovsky & Swan}
\affiliation{The University of Texas at Austin}
 
\abstract{}

\keywords{behavioral observation; interval recording; alternating Poisson process; Markov chain}

\authornote{James E. Pustejovsky, Department of Educational Psychology, University of Texas at Austin. Daniel M. Swan, Department of Educational Psychology, University of Texas at Austin.

Address correspondence to James E. Pustejovsky, Department of Educational Psychology, University of Texas at Austin, 1 University Station D5800, Austin, TX 78712. Email: pusto@austin.utexas.edu.}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}


\maketitle

Measurements derived from systematic, direct observation of human behavior are used in many areas of psychological and educational research. For example, direct observation of student classroom behavior is a primary component of several existing instruments for screening and diagnosis of emotional and behavioral problems \citep{Volpe2005observing}; measures based on direct observation of childrens' challenging behavior in home settings have been employed as pre- and post-test measures in randomized trials of behavioral interventions \citep[e.g.,][]{Durand2012positive}; and direct observation of infant-parent interaction patterns is employed in studies of child development \citep{Mann1991time} and cross-cultural differences \citep{Bornstein2002measurement}. Direct observation also plays a particularly prominent role in single-case research, where it is used to measure changes in behavior over time and assess individual responses to intervention \citep{Kazdin2011single}.

\todo[inline]{Define prevalence and incidence.}

Several commonly used systems for collecting behavioral data do not capture a complete record of the behavior during an observation session, but rather involve making observations only intermittently. Among intermittent recording procedures, the three main procedures are momentary time sampling, partial interval recording, and whole interval recording. In all three methods, an observation session is divided into a fixed number of equally spaced intervals, of perhaps 10 or 15 s in length, and a binary data-point is recorded for each interval. The systems differ only in the rule for scoring each interval. Using momentary time sampling (MTS), an interval is scored as a one if a behavioral event is happening during the final moment of the interval (and is otherwise scored as a zero). Using partial interval recording (PIR), an interval is scored as a one if the behavior occurs at any point during the interval. Using whole interval recording (WIR), an interval is scored as a one only if the behavior occurs for the entire duration of the interval. In some PIR and WIR systems, a small length of time is left between each interval so that the observer does not have to maintain continuous attention. 

In many applications, the interval-by-interval data generated by these recording systems is summarized by the proportion of intervals scored as a one. Often, only this summary proportion is used for later analysis, where it is interpretted as a measure of prevalence. Under what circumstances is it reasonable to reduce the data to the summary proportion? We argue that this depends on which recording system is used to collect the measurements. 

Under quite general modeling assumptions, the proportion of MTS intervals is an unbiased estimate of prevalence \citep{Rogosa1991statistical}. Thus, reducing the data to the summary proportion may be quite reasonable if the investigator's interest is solely in the prevalence of the behavior. However, simple summaries of MTS data do not provide a clear measure of the behavior's incidence. Even if not of substantive interest, estimates of incidence are  are necessary for assessing the magnitude of measurement error in the prevalence estimates. 

\citet{Brown1977estimation} described a method for estimating both prevalence and incidence from MTS data. Their approach was to first posit a stochastic process for the underlying stream of behavior, as perceived by the observer, and then to consider the implications of observing the process intermittently via an MTS system. The particular model they considered was an Alternating Poisson Process, which is a simple, two-state continuous time Markov chain where transitions between states follow exponential distributions. The Alternating Poisson Process implies that interval-by-interval MTS scores follow a discrete-time Markov chain. Under the model, \citet[see also \citealp{Griffin1983parametric}]{Brown1977estimation} provided closed-form expressions for the maximum likelihood estimators of prevalence and incidence and the associated asymptotic covariance matrix.

Unlike MTS, PIR and WIR systems do not produce clearly interpretable summary measurements. Rather, the PIR summary proportion systematically over-estimates prevalence and the WIR summary proportion systematically under-estimates prevalence; in both cases, the extent of the bias depends on the incidence of the behavior as well as operational features of the recording system \citep{Kraemer1979one, Rogosa1991statistical}, making the construct interpretation of such data quite difficult\todo{Cite example about incorrect inferences based on PIR?}. Consequently, methodologists have long argued against the use of PIR and WIR systems \citep[cf.]{Altmann1974observational, Mann1991time, Lane2014using}. Despite such objections, the systems remain in common use, particularly as part of behavioral time series designs and single-case research \citep{Rapp2007interval, Mudford2009continuous, Lane2014using}. 

Little previous research has considered methods of analyzing PIR and WIR data beyond using the summary proportion. For PIR data, \citet{Altmann1970estimating} proposed a transformation of the summary proportion as an estimate of incidence, motivated by a model in which the new behavioral episodes follow a Poisson process. However, their model applies only to ``event'' behaviors \citep{Altmann1974observational}, where the duration of individual episodes is negligible and prevalence is not a salient feature. In contrast, the Poisson process model is clearly inappropriate for ``state'' behaviors, in which individual episodes of behavior have positive length, and where the prevalence of the behavior is of interest. \citet{Suen1986post, Suen1989analyzing} have proposed a method for obtaining estimates of prevalence and incidence from PIR data, provided that the behavior stream conforms to certain conditions. However, their proposed procedure is not motivated by any explicit data-generating process, and later simulation studies reported that the method produces badly biased estimates \citep[sec. 5.2]{Rogosa1991statistical}. \todo[inline]{Add short discussion of \citet{Pustejovsky2014four}.}

This paper examines models for PIR and WIR data, from which principled estiamtes of prevalence and incidence can be obtained. Following \citet{Brown1977estimation}, we use an Alternating Poisson Process for the underlying behavior stream to derive a model for the interval-by-interval scores. Under this model, maximum likelihood estimators for prevalence and incidence can be obtained using conventional numerical techniques (although they do not have closed-form expression). To remedy some problems with the maximum likelihood estimators, we introduce penalized likelihood estimators that have better operating characteristics and that can be tailored to express prior information about the behavioral parameters. We use a parametric bootstrap procedure for obtaining interval estimates.

\todo[inline]{Brief discussion of penalized likelihood estimation in other contexts.}

The remainder of the paper is organized as follows. In the next section, we introduce the Alternating Poisson Process model for the behavior stream and lay out common notation. In the following section, we review the estimators described by \citet{Brown1977estimation} for MTS data and propose alternative estimators based on penalized likelihood. In the following section, we develop the Alternating Poisson Process model to handle PIR data, then study penalized likelihood estimators for prevalence and incidence. Finally, we present a brief empirical application and discuss limitations and future research directions.\todo{Revise this.}

\section{Alternating Poisson Process models}
\label{sec:APP}

The Alternating Poisson Process is a stochastic model that can be used to describe a stream of behavior, as it is perceived in time. The model applies to state behaviors, where each episode has a non-negligible duration. It is assumed that the behavior is either occurring or not occurring at any given point in time, so that the perceived behavior stream can be described in terms of two components: sequentially ordered, non-overlapping episodes of behavior, which we will call \textit{event durations}, and spans of time in between episodes, which we will call \textit{interim times}. Let $\{Z(t), 0 \leq t\}$ denote the state of the behavior stream over the course of an observation session, where $Z(t) = 1$ indicates that an event is occurring at time $t$ and $Z(t) = 0$ otherwise.

In the Alternating Poisson Process, it is assumed that event durations and interim times are mutually independent, random quantities, that the event durations follow an exponential distribution with mean $\mu > 0$, and that the interim times follow an exponential distribution with mean $\lambda > 0$.  Under the model, the prevalence of the behavior is equal to the ratio of $\mu$ to the sum of $\mu$ and $\lambda$ and the incidence of the behavior is equal to the reciprocal of the sum of $\mu$ and $\lambda$. We will denote prevalence by $\phi$, where $0 < \phi < 1$, and incidence by $\zeta$, where $\zeta > 0$. 

Finally, we assume that the process is in equilibrium, with $\Pr\left(Y(0) = 1\right) = \phi$. This assumption implies that there is a constant marginal probability of observing an event at any given point in time\todo{Expand further--when would this not apply/be inappropriate?}.

The Alternating Poisson Process is a special case of a continuous time Markov chain, and thus has the Markov property that the the future state of the behavior depends only on the current state, but not on the past history of the behavior. More precisely, the probability that a behavior will be occurring $t$ seconds into the future is independent of the state of the behavior for $0 \leq r < s$: 
\begin{equation}
\label{eq:Markov}
\Pr\left[Z(s + t) = 1 \left| Z(s) = a, Z(r): 0 \leq r < s \right.\right] = \Pr\left[ Z(s + t) = 1 \left| Z(s) = a \right.\right]
\end{equation}
for $a = 0,1$ and $s,t \geq 0$ \citep[Thm. 6.1]{Kulkarni2010modeling}. The assumption that the process is in equilibrium further implies that the probability that a behavior will be occurring $t$ seconds into the future does not depend on the current time, i.e.,  
\begin{equation}
\label{eq:equilibrium}
\Pr\left[Z(s + t) = 1 \left| Z(s) = a\right.\right] = \Pr\left[ Z(t) = 1 \left| Z(0) = a \right.\right].
\end{equation}
Let $p_a(t)$ denote the conditional probability that an event will be occurring $t$ seconds into the future, given that the behavior is currently in state $a$, for $a = 0,1$. These conditional probabilities can be expressed as follows:
\begin{equation}
\begin{aligned}
p_0(t) &= \Pr(Z(t) = 1 | Z(0) = 0) = \phi \left[1 - \exp\left(\frac{- t \zeta}{\phi (1 - \phi)}\right)\right] \\
p_1(t) &= \Pr(Z(t) = 1 | Z(0) = 1) = \phi + (1 - \phi) \exp\left(\frac{- t \zeta}{\phi (1 - \phi)}\right)
\end{aligned}
\end{equation}
\citep[Eq. 6.17]{Kulkarni2010modeling}.

\subsection{Momentary Time Sampling}
\label{subsec:MTS}

Consider observing a behavior stream generated by the Alternating Poisson Process and recording observations using momentary time sampling with $K + 1$ recording times, equally spaced at intervals of length $c$. Denote the recorded data by the sequence of binary indicator variables $X_0,X_1,...,X_K$. The MTS interval data are a record of the state of the behavior stream process at fixed moments in time: $X_k = Z(ck)$ for $k = 0,...,K$. 

\citet{Brown1977estimation} demonstrated that MTS data follow a two-state, discrete-time Markov chain process with transition probabilities $Pr(X_k = 1 | X_{k-1} = a) = p_a(c)$ and $Pr(X_k = 0 | X_{k-1} = a) = 1 - p_a(c)$ for $a = 0,1$. Therefore, sufficient statistics for the process are given by the table counting the number of transitions with $(X_{k-1} = a, X_k = b)$ for $a,b = 0,1$ and $k = 1,...,K$; let $n_{ab} = \sum_{k=1}^K I(X_{k-1} = a, X_k = b)$. Conditioning on $X_0$, the log-likelihood of MTS data is then given by \begin{equation}
\begin{aligned}
\label{eq:MTS_loglik}
l_{MTS}(\phi, \zeta) &= n_{01} \log \phi + n_{10} \log\left(1 - \phi\right) \\
& \qquad \qquad + \left(n_{01} + n_{10}\right) \log \left[1 - \exp\left(\frac{-\zeta c}{\phi (1 - \phi)}\right)\right] \\
& \qquad \qquad \qquad \qquad + n_{00} \log\left[1 - \phi + \phi \exp\left(\frac{-\zeta c}{\phi (1 - \phi)}\right)\right]\\
& \qquad \qquad \qquad \qquad \qquad \qquad + n_{11}\log\left[\phi + \left(1 - \phi\right)\exp\left(\frac{-\zeta c}{\phi (1 - \phi)}\right)\right].
\end{aligned}
\end{equation}
Let $\hat{p}_0 = n_{01}/ \left(n_{00} + n_{01}\right)$ and $\hat{p}_1 = n_{11} / \left(n_{10} + n_{11}\right)$. \citet{Brown1977estimation} showed that the maximum likelihood estimate of $\zeta$ exists only when $\hat{p}_0 < \hat{p}_1$. When this condition holds, the maximum likelihood estimates of $\phi$ and $\zeta$ are given by 
\begin{equation}
\label{eq:MTS_mle}
\hat\phi_{MTS} = \frac{\hat{p}_0}{\hat{p}_0 + 1 - \hat{p}_1} \qquad \text{and} \qquad
\hat\zeta_{MTS} = \frac{-\hat{p}_0 \left(1 - \hat{p}_1\right) \log(\hat{p}_1 - \hat{p}_0)}{c \left(\hat{p}_0 + 1 - \hat{p}_1\right)^2}.
\end{equation}
If $\hat{p}_0 \geq \hat{p}_1$, then the maximum likelihood estimator of $\phi$ is still well-defined and equal to $\hat\phi_{MTS} = \left(n_{01} + n_{11}\right) / K$. 



% latex table generated in R 3.1.0 by xtable 1.7-3 package
% Mon Jan 19 15:06:29 2015
\begin{table}[b]
\centering
\caption{Proportion of 2000 simulated MTS samples (K = 40) in which $0 < \hat\phi_{MTS} < 1$ and $0 < \hat\zeta_{MTS} < \infty$.} 
\label{tab:MTS_zeta_valid}
\begin{tabular}{rrrrrrrr}
  \hline
 & $\zeta = 0.02$ & 0.05 & 0.1 & 0.2 & 0.25 & 0.4 & 0.5 \\ 
  \hline
$\phi = 0.1$ & 0.43 & 0.63 & 0.64 & 0.45 & 0.37 & 0.29 & 0.26 \\ 
  0.2 & 0.45 & 0.80 & 0.90 & 0.84 & 0.79 & 0.59 & 0.49 \\ 
  0.3 & 0.46 & 0.84 & 0.96 & 0.96 & 0.94 & 0.73 & 0.64 \\ 
  0.4 & 0.43 & 0.87 & 0.98 & 0.99 & 0.97 & 0.82 & 0.71 \\ 
  0.5 & 0.45 & 0.88 & 0.99 & 1.00 & 0.98 & 0.84 & 0.71 \\ 
   \hline
\end{tabular}
\end{table}


The probability that the maximum likelihood estimators are undefined or fall outside of the parameter space is not trivial, even when $K$ is relatively large. Note that in order for the estimates to fall strictly within the parameter space, both a 0-1 transition and a 1-0 transition must be observed, so that $\hat{p}_0 > 0$, $\hat{p}_1 < 1$. Table \ref{tab:MTS_zeta_valid} reports the proportion of 2000 simulated samples in which $0 < \hat\phi_{MTS} < 1$ and $0 < \hat\zeta_{MTS} < \infty$, with $K = 40$ and $\zeta$ scaled in terms of the interval length. Values of $\phi > 0.5$ are omitted because the behavior of the MTS estimators is symmetric about $\phi = 0.5$. The proportion of estimates falling within in the parameter space decreases as prevalence becomes more extreme and as incidence becomes very infrequent or very frequent. The high proportion of samples in which the estimators are undefined is a substantial drawback to the use of maximum likelihood.

\subsection{Partial Interval Recording}
\label{subsec:PIR}

Consider observing a behavior stream generated by the Alternating Poisson Process and recording observations using partial interval recording. Suppose that one observes $K$ intervals, where each interval includes $c$ seconds of active observation time followed by $d$ seconds of recording time. Let time $t_k = (k-1)(c + d)$ denote the beginning of interval $k$. Let $U_k$ indicate the PIR score from interval $k$, corresponding to the time from $t_k$ to $t_k + c$. Following the PIR system, $U_k = 1$ if is the behavior occurs at any point during the active portion of interval, and $U_k = 0$ otherwise. In terms of the behavior stream process, 
\begin{equation}
U_k = I\left[ 0 < \int_0^c Z\left(t_k + s \right) ds\right]
\end{equation}
for $k = 1,...,K$, where $\int_0^c$ denote the definite integral over the half-open interval $[0,c)$.

Under the assumptions of the Alternating Poisson Process, the joint distribution of $U_1,...,U_K$ can be derived as follows. Let $\psi_k, k = 2,...,K$ denote the probability than the behavior is occurring at time $t_k = (k-1)(c + d)$, given the partial interval record up to that time. For ease of notation, set $\psi_1 = \phi$, which follows from the assumption that the process is in equilibrium. We show in Appendix \ref{app:PIR_derivation} that  
\begin{equation}
\label{eq:psi_k}
\begin{aligned}
\psi_k &= \Pr\left[ Z(t_k) = 1 \left| U_1,...,U_{k-1}\right.\right] \\
 &= \left[\frac{\psi_{k-1} p_1(c + d) + (1 - \psi_{k-1}) \left[p_0(c + d) - p_0(d) \exp\left(\frac{- \zeta c}{1 - \phi}\right)\right]}{1 - (1 - \psi_{k-1})\exp\left( \frac{-\zeta c}{1 - \phi}\right)}\right]^{u_{k-1}} \left[p_0(d)\right]^{(1 - u_{k-1})}.
\end{aligned}
\end{equation}
Note that $Z(t_k) = 1$ implies that $U_k = 1$ with certainty, while 
\[ \Pr\left(U_k = 1\left| Z(t_k) = 0\right.\right) = 1 - \exp\left( \frac{-\zeta c}{1 - \phi}\right).\]
It follows from the Markov property of the Alternating Poisson Process that 
\begin{align*}
\Pr\left(U_k = 1 \left| U_1,...,U_{k-1}\right.\right) &= \psi_k \Pr\left(U_k = 1 \left| Y(t_k) = 1)\right.\right)  + (1 - \psi_k)\Pr\left(U_k = 1 \left| Y(t_k) = 0)\right.\right) \\
&= 1 - (1 - \psi_k)\exp\left( \frac{-\zeta c}{1 - \phi}\right).
\end{align*}
The joint distribution of $U_1,...,U_K$ can therefore be expressed as 
\begin{align*}
\Pr\left(U_1=u_1,...,U_K = u_K\right) &= \Pr\left(U_1=u_1\right) \prod_{k=2}^K \Pr\left(U_k=u_k \left| U_1,...,U_{k-1}\right.\right) \nonumber \\
&= \prod_{k=1}^K \left[1 - (1 - \psi_k)\exp\left( \frac{-\zeta c}{1 - \phi}\right) \right]^{u_k} \left[(1 - \psi_k)\exp\left( \frac{-\zeta c}{1 - \phi}\right)\right]^{(1 - u_k)}.
\end{align*}

The log-likelihood of $\phi$ and $\zeta$, given observed PIR data $u_1,...,u_K$, is
\begin{align}
\label{eq:log_lik}
l_{PIR}\left(\phi,\zeta\right) = \sum_{k=1}^K & u_k \ln\left[1 - (1 - \psi_k)\exp\left( \frac{-\zeta c}{1 - \phi}\right)\right]  + (1 - u_k)\left[\ln\left(1 - \psi_k \right) - \frac{\zeta c}{1 - \phi}\right].
\end{align}
Maximum likelihood estimates are obtained by maximizing $l_{PIR}$ using a numerical algorithm. Because the conditional probabilities $\psi_1,...,\psi_K$ are defined recursively, it is cumbersome and computationally expensive to evaluate the score function corresponding to this likelihood. The simulation study reported in the next subsection therefore uses the Nelder-Mead algorithm, which does not require evaluation of the score function, with the likelihood expressed in terms of the unbounded parameters $\logit(\phi)$ and $\log(\zeta)$.



% latex table generated in R 3.1.0 by xtable 1.7-3 package
% Mon Jan 19 15:06:29 2015
\begin{table}[b]
\centering
\caption{Proportion of 2000 simulated PIR samples (K = 40) in which  $|\text{logit}(\hat\phi)| < 8$ and $|\text{log}(\hat\zeta)| < 8$.} 
\label{tab:PIR_ests_valid}
\begin{tabular}{rrrrrrrr}
  \hline
 & $\zeta = 0.02$ & 0.05 & 0.1 & 0.2 & 0.25 & 0.4 & 0.5 \\ 
  \hline
$\phi = 0.1$ & 0.59 & 0.83 & 0.94 & 0.94 & 0.90 & 0.78 & 0.72 \\ 
  0.2 & 0.67 & 0.91 & 0.98 & 0.99 & 0.98 & 0.92 & 0.84 \\ 
  0.3 & 0.74 & 0.94 & 0.99 & 1.00 & 1.00 & 0.94 & 0.87 \\ 
  0.4 & 0.78 & 0.96 & 1.00 & 1.00 & 0.99 & 0.93 & 0.86 \\ 
  0.5 & 0.77 & 0.96 & 0.99 & 0.99 & 0.98 & 0.89 & 0.80 \\ 
  0.6 & 0.75 & 0.94 & 0.97 & 0.96 & 0.92 & 0.79 & 0.67 \\ 
  0.7 & 0.68 & 0.87 & 0.92 & 0.85 & 0.78 & 0.56 & 0.38 \\ 
  0.8 & 0.60 & 0.76 & 0.77 & 0.56 & 0.42 & 0.16 & 0.09 \\ 
  0.9 & 0.47 & 0.48 & 0.32 & 0.08 & 0.04 & 0.00 & 0.00 \\ 
   \hline
\end{tabular}
\end{table}


Just as with MTS data, maximum likelihood estimates based on PIR data do not always fall within the parameter space. Table \ref{tab:PIR_ests_valid} reports the proportion of 2000 simulated samples in which the MLEs based on PIR data are within the parameter space, again with $K = 40$ and $\zeta$ scaled in terms of the interval length. Because we use numerical maximization, the results of the maximization routine are never precisely on the borders of the parameter space. We therefore use boundaries of $|\logit \ \hat\phi| < 8$ and $|\log \hat\zeta| < 8$ to define the edges of the parameter space.\todo{Discuss table.}

In addition to returing estimates that are on the edges of the parameter space, the maximum likelihood estimators have the further disadvantage of being somewhat sensitive to initialization values. The likelihood surface becomes very flat when the PIR scores are near ceiling or floor levels, making it difficult to numerically identify the maximum. For the implementation of the estimators in the accompanying R package, the consequence is that drastically different estimates can be returned depending on the initialization values of the algorithm. Together with the possibility of obtaining estimates on the edges of the parameter space, the algorithmic instability of the maximum likelihood estimators motivates our investigation of alternative estimators that incorporate penalty functions.  

\subsection{Whole Interval Recording}
\label{sec:WIR}

Consider observing a behavior stream generated by the Alternating Poisson Process and recording observations using whole interval recording. As with PIR, suppose that one observes $K$ intervals, where each interval includes $c$ seconds of active observation time followed by $d$ seconds of recording time. Let $W_k$ indicate the WIR score from interval $k$, corresponding to the time from $t_k$ to $t_k + c$. Following the WIR system, $W_k = 1$ if is the behavior occurs for the duration of the active portion of interval, and $W_k = 0$ otherwise. Formally, 
\begin{equation}
W_k = I\left[ c = \int_0^c Z\left(t_k + s \right) ds\right]
\end{equation}
for $k = 1,...,K$. 

Using the WIR system to score a state behavior is logically equivalent to using PIR to score the absence of the behavior. WIR data can therefore be modeled just as PIR data, after an appropriate change of parameters. Specifically, the log-likelihood for WIR data under the Alternating Poisson Process can be written in terms of the log-likelihood for PIR data as
\begin{equation}
l_{WIR}\left(\phi, \zeta | W_1 = w_1,...,W_k = w_k \left) = l_{PIR}\right(1 - \phi, \zeta | U_1 = 1 - w_1,...,U_K = 1 - w_k\right).
\end{equation}
The equivalence of the two system implies that maximum likelihood and penalized likelihood estimators based on WIR data can be obtained using the algorithms developed for PIR. 

\section{Penalized likelihood estimators}

Potential priors:
\begin{itemize}
\item Independent $\Gamma(k, \theta)$ priors on $\mu,\lambda$ scale, which translates to $\phi \sim Beta(k_\mu, k_\lambda)$ and $1 / \zeta \sim \Gamma(k_\mu + k_\theta, \theta)$. Need to have $k_\mu, k_\lambda > 1$ in order for estimates to remain within parameter space. 
\item Independent normal priors on $\logit \phi, \log \zeta$.
\end{itemize}

\subsection{Finite-sample performance: MTS}

\subsection{Finite-sample performance: PIR}

\section{Application}
\label{sec:application}

\section{Discussion}
\label{sec:discussion}

\bibliographystyle{apacite}
\bibliography{\bibfile}
 
\appendix

\section{Derivation of PIR model}
\label{app:PIR_derivation}

The joint distribution of PIR observations depends on the conditional probabilities $\psi_k = \Pr\left[ Z(t_k) = 1 \left| U_1,...,U_{k-1}\right.\right]$. This appendix provides a derivation of Expression (\ref{eq:psi_k}) in terms of the parameters of the Alternating Poisson Process. Note that $U_{k-1} = 0$ implies that $Z(t_k + c) = 0$. It follows from the Markov property that 
\begin{multline*}
\Pr\left(Z(t_k) = 1 \left| U_1 = u_1,...,U_{k-2} = u_{k-2}, U_{k-1} = 0 \right.\right) \\ 
= \Pr\left(Z(t_k) = 1 \left| Z(t_{k-1} + c) = 0 \right.\right) = p_0(d).
\end{multline*}
Next, observe that \[
\Pr\left(Z(t_k) = 1, U_{k-1} = 1 \left| Z(t_{k-1}) = 1 \right.\right) = \Pr\left(Z(t_k) = 1 \left| Z(t_{k-1}) = 1 \right.\right) = p_1(c + d) \]
and \begin{align*}
\Pr &\left(Z(t_k) = 1, U_{k-1} = 1 \left| Z(t_{k-1}) = 0 \right.\right) \\
& \qquad \qquad = \int_0^c p_1(c - t) \frac{ \zeta \exp(-t \zeta / (1 - \phi))}{(1 - \phi)} dt \\
& \qquad \qquad  = \phi \left[ 1 - \exp\left(\frac{- \zeta (c + d)}{\phi(1 - \phi)}\right) - \exp\left(\frac{- \zeta c}{1 - \phi}\right) + \exp\left(\frac{- \zeta (\phi c + d)}{\phi(1 - \phi)}\right)\right] \\
& \qquad \qquad = p_0(c + d) - p_0(d) \exp\left(\frac{- \zeta c}{1 - \phi}\right).
\end{align*}
It follows further that \begin{multline*}
\Pr\left(Z(t_k) = 1, U_{k-1} = 1 \left| U_1,...,U_{k-2} \right.\right) \\
= \psi_{k-1} p_1(c + d) + (1 - \psi_{k-1}) \left[p_0(c + d) - p_0(d) \exp\left(\frac{- \zeta c}{1 - \phi}\right)\right]
\end{multline*}
and
\begin{multline*}
\Pr\left(Z(t_k) = 1 \left| U_1 = u_1,...,U_{k-2} = u_{k-2}, U_{k-1} = 1 \right.\right) \\
= \frac{\psi_{k-1} p_1(c + d) + (1 - \psi_{k-1}) \left[p_0(c + d) - p_0(d) \exp\left(\frac{- \zeta c}{1 - \phi}\right)\right]}{1 - (1 - \psi_{k-1})\exp\left( \frac{-\zeta c}{1 - \phi}\right)}.
\end{multline*}
Thus, $\psi_k$ can be written as a function of $\psi_{k-1}$ and $u_{k-1}$, as given in (\ref{eq:psi_k}).

\end{document}
