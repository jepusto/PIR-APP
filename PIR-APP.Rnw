\documentclass[man, noextraspace, floatsintext]{apa6}
\newcommand{\bibfile}{C:/Users/jep2963/Documents/Bibliography/Behavioral_observation-APP}  

\usepackage[natbibapa]{apacite}
\newcommand{\citetal}[1]{\shortcites{#1}\citet{#1}}

\raggedbottom

\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{graphicx}

\usepackage{fixltx2e}
\usepackage{subcaption}
\usepackage{float}

\usepackage{array}
\usepackage{multirow}
\usepackage{rotating}
\setlength{\rotFPtop}{0pt plus 1fil}
\usepackage[draft]{changes}

\geometry{twoside=false, top=1in, bottom=1in, left=1in, right=1.2in}
\usepackage[textwidth=1in, textsize=tiny]{todonotes}

\newcommand{\Prob}{\text{Pr}}
\newcommand{\E}{\text{E}}
\newcommand{\Cov}{\text{Cov}}
\newcommand{\corr}{\text{corr}}
\newcommand{\Var}{\text{Var}}
\newcommand{\iid}{\stackrel{\text{iid}}{\sim}}
\newcommand{\logit}{\text{logit}}
\newcommand{\cll}{\text{cll}}


\title{An Alternating Poisson Process model for estimating prevalence and incidence from interval recording data}
\shorttitle{ALTERNATING POISSON PROCESS FOR INTERVAL RECORDING DATA}
\author{James E. Pustejovsky and Daniel M. Swan}
\leftheader{Pustejovsky & Swan}
\affiliation{The University of Texas at Austin}
 
\abstract{}

\keywords{behavioral observation; interval recording; alternating Poisson process; Markov chain}

\authornote{James E. Pustejovsky, Department of Educational Psychology, University of Texas at Austin. Daniel M. Swan, Department of Educational Psychology, University of Texas at Austin.

Address correspondence to James E. Pustejovsky, Department of Educational Psychology, University of Texas at Austin, 1 University Station D5800, Austin, TX 78712. Email: pusto@austin.utexas.edu.}


\begin{document}
<<setup, include=FALSE, cache=FALSE>>=
library(knitr)
library(xtable)
library(ARPobservation)
library(plyr)
library(reshape2)

# set global chunk options
opts_chunk$set(echo = FALSE, cache = FALSE, fig.path='fig/', fig.align='center', fig.show='hold')
@

\maketitle

Measurements derived from systematic, direct observation of human behavior are used in many areas of psychological research.\todo{For example...}

\todo[inline]{Define prevalence and incidence.}

Several commonly used systems for collecting behavioral data do not capture a complete record of the behavior during an observation session, but rather involve making observations intermittently, typically at fixed intervals in time. Three main interval recording systems are momentary time sampling, partial interval recording, and whole interval recording. In all three methods, an observation session is divided into a fixed number of equally spaced intervals, of perhaps 10 or 15 s in length, and a binary data-point is recorded for each interval. The systems differ only in the rule for scoring each interval. Using momentary time sampling (MTS), an interval is scored as a one if a behavioral event is happening during the final moment of the interval (and is otherwise scored as a zero). Using partial interval recording (PIR), an interval is scored as a one if the behavior occurs at any point during the interval. Using whole interval recording (WIR), an interval is scored as a one only if the behavior occurs for the entire duration of the interval. In some PIR and WIR systems, a small length of time is left between each interval so that the observer does not have to maintain continuous attention. 

In many contexts, the interval-by-interval data generated by these recording systems is summarized by the proportion of intervals scored as a one. Often, only this summary proportion is used for later analysis, where it is commonly interpretted as a measure of prevalence. If the investigator's interest is solely in the prevalence of the behavior, it may be quite reasonable to reduce MTS data to its summary proportion because, under quite general modeling assumptions, the proportion of MTS intervals is an unbiased estimate of prevalence \citep{Rogosa1991statistical}. However, simple summaries of MTS data do not provide a clear measure of the behavior's incidence. Even if not of substantive interest, estimates of incidence are nonetheless useful for providing a fuller characterization of the behavior under study and necessary for assessing the magnitude of measurement error in the prevalence estimates. 

\citet{Brown1977estimation} described a method for estimating prevalence and incidence from MTS data. Their approach was to first posit a stochastic process for the underlying stream of behavior, as perceived by the observer, and then to consider the implications of observing the process intermittently via an MTS system. The particular model they considered was an Alternating Poisson Process, which is a simple, two-state continuous time Markov chain where transitions between states follow exponential distributions. The Alternating Poisson Process implies that interval-by-interval MTS scores follow a discrete-time Markov chain. Under the model, \citet[see also \citealp{Griffin1983parametric}]{Brown1977estimation} provided closed-form expressions for the maximum likelihood estimators of prevalence and incidence and the associated asymptotic covariance matrix.

Unlike MTS, PIR and WIR do not produce clearly interpretable summary measurements. Rather, the proportion of PIR intervals systematically over-estimates prevalence and the proportion of WIR intervals systematically under-estimates prevalence; in both cases, the extent of the bias depends on the incidence of the behavior as well as operational features of the recording system \citep{Kraemer1979one, Rogosa1991statistical}, making the construct interpretation of such data quite difficult\todo{Cite example about incorrect inferences based on PIR?}. Consequently, methodologists have long argued against the use of PIR and WIR systems \citep[cf.]{Altmann1974observational, Mann1991time, Lane2014using}. Despite such objections, the systems remain in common use, particularly as part of behavioral time series designs and single-case research \citep{Rapp2007interval, Mudford2009continuous, Lane2014using}. 

This paper examines methods for estimating prevalence and incidence based on PIR and WIR data.\footnote{\citet{Suen1986post, Suen1989analyzing} also proposed a method for obtaining estimates of prevalence and incidence from PIR data, provided that the behavior stream conforms to certain conditions. However, the proposed procedure is not motivated by any explicit data-generating process, and later simulation studies reported that the method produces badly biased estimates \citep[sec. 5.2]{Rogosa1991statistical}. Therefore, we do not consider the method here.} Following \citet{Brown1977estimation}, we use an Alternating Poisson Process for the underlying behavior stream to derive a model for the interval-by-interval scores. Under this model, maximum likelihood estimators for prevalence and incidence can be obtained using conventional numerical techniques (although they do not have closed-form expression), but are sometimes unstable and sometimes return estimates on the boundaries of the parameter space. To remedy these deficits, we introduce penalized likelihood estimators that have better operating characteristics and that can be tailored to express prior information about the behavioral parameters; we also describe a parametric bootstrap procedure for obtaining interval estimates.

\todo[inline]{Brief discussion of penalized likelihood estimation in other contexts.}

The remainder of the paper is organized as follows. In the next section, we introduce the Alternating Poisson Process model for the behavior stream and lay out common notation. In the following seciton, we review the estimators described by \citet{Brown1977estimation} for MTS data and propose alternative estimators based on penalized likelihood. In the following section, we develop the Alternating Poisson Process model to handle PIR data, then study penalized likelihood estimators for prevalence and incidence. Finally, we present a brief empirical application and discuss limitations and future research directions.

\section{The Alternating Poisson Process}
\label{sec:APP}

The Alternating Poisson Process is a stochastic model that can be used to describe a stream of behavior, as it is perceived in time. The model applies to patterns of behavior where each episode has a non-negligible duration, or what \citet{Altmann1974observational} termed ``state'' behaviors.\footnote{In contrast, ``event'' behaviors are those where the duration of individual episodes is negligible or not salient \citep{Altmann1974observational}. The Alternating Poisson Process is a less useful model for such behaviors.} It is assumed that the behavior is either occurring or not occurring at any given point in time, so that the perceived behavior stream can be described in terms of two components: sequentially ordered, non-overlapping episodes of behavior, which we will call \textit{event durations}, and spans of time in between episodes, which we will call \textit{interim times}. Let $\{Y(t), 0 \leq t\}$ denote the state of the behavior stream over the course of an observation session, where $Y(t) = 1$ indicates that an event is occurring at time $t$ and $Y(t) = 0$ otherwise.

In the Alternating Poisson Process, it is assumed that event durations and interim times are mutually independent, random quantities, that the event durations follow an exponential distribution with mean $\mu > 0$, and that the interim times follow an exponential distribution with mean $\lambda > 0$.  Under the model, the prevalence of the behavior is equal to the ratio of $\mu$ to the sum of $\mu$ and $\lambda$ and the incidence of the behavior is equal to the reciprocal of the sum of $\mu$ and $\lambda$. We will denote prevalence by $\phi$, where $0 < \phi < 1$, and incidence by $\zeta$, where $\zeta > 0$. We further assume that the process is in equilibrium, with $\Pr\left(Y(0) = 1\right) = \phi$. This assumption implies that there is a constant marginal probability of observing an event at any given point in time\todo{Expand further--when would this not apply/be inappropriate?}.

The Alternating Poisson Process is a special case of a continuous time Markov chain, and thus has the Markov property that the the future state of the behavior depends only on the current state, but not on the past history of the behavior. More precisely, the probability that a behavior will be occurring $t$ seconds into the future is independent of the state of the behavior for $0 \leq r < s$: 
\begin{equation}
\label{eq:Markov}
\Pr\left[Y(s + t) = 1 \left| Y(s) = a, Y(r): 0 \leq r < s \right.\right] = \Pr\left[ Y(s + t) = 1 \left| Y(s) = a \right.\right]
\end{equation}
for $a = 0,1$ and $s,t \geq 0$ \citep[Thm. 6.1]{Kulkarni2010modeling}. The assumption that the process is in equilibrium further implies that the probability that a behavior will be occurring $t$ seconds into the future does not depend on the current time, i.e.,  
\begin{equation}
\label{eq:equilibrium}
\Pr\left[Y(s + t) = 1 \left| Y(s) = a\right.\right] = \Pr\left[ Y(t) = 1 \left| Y(0) = a \right.\right].
\end{equation}
Let $p_a(t)$ denote the conditional probability that an event will be occurring $t$ seconds into the future, given that the behavior is currently in state $a$, for $a = 0,1$. These conditional probabilities can be expressed as follows:
\begin{equation}
\begin{aligned}
p_0(t) &= \Pr(Y(t) = 1 | Y(0) = 0) = \phi \left[1 - \exp\left(\frac{- t \zeta}{\phi (1 - \phi)}\right)\right] \\
p_1(t) &= \Pr(Y(t) = 1 | Y(0) = 1) = \phi + (1 - \phi) \exp\left(\frac{- t \zeta}{\phi (1 - \phi)}\right)
\end{aligned}
\end{equation}
\citep[Eq. 6.17]{Kulkarni2010modeling}.

\section{Momentary Time Sampling}
\label{sec:MTS}

Consider observing a behavior stream generated by the Alternating Poisson Process and recording observations using momentary time sampling. Suppose that the presence or absence of a behavior is noted at each of $K+1$ times, equally spaced at intervals of length $c$. Denote the recorded data by the sequence of binary indicator variables $X_0,X_1,...,X_K$, where $X_k = Y(ck)$ for $k = 0,...,K$. 

\citet{Brown1977estimation} demonstrated that MTS data form a simple, two-state, discrete-time Markov chain with transition probabilities $Pr(X_k = 1 | X_{k-1} = a) = p_a(c)$ and $Pr(X_k = 0 | X_{k-1} = a) = 1 - p_a(c)$ for $a = 0,1$. Therefore, sufficient statistics for the process are given by the table counting the number of transitions with $(X_{k-1} = a, X_k = b)$ for $a,b = 0,1$ and $k = 1,...,K$; let $n_{ab} = \sum_{k=1}^K I(X_{k-1} = a, X_k = b)$. Conditioning on $X_0$, the log-likelihood of MTS data is then given by \begin{equation}
\begin{aligned}
\label{eq:MTS_loglik}
l_{MTS}(\phi, \zeta) &= \left(n_{00} + n_{01}\right) \log \phi + \left(n_{10} + n_{11}\right) \log\left(1 - \phi\right) \\
& \qquad \qquad + \left(n_{01} + n_{10}\right) \log \left[1 - \exp\left(\frac{-\zeta c}{\phi (1 - \phi)}\right)\right] \\
& \qquad \qquad \qquad \qquad + n_{00} \log\left[\frac{1}{\phi} - 1 + \exp\left(\frac{-\zeta c}{\phi (1 - \phi)}\right)\right]\\
& \qquad \qquad \qquad \qquad \qquad \qquad + n_{11}\log\left[\frac{\phi}{1 - \phi} + \exp\left(\frac{-\zeta c}{\phi (1 - \phi)}\right)\right].
\end{aligned}
\end{equation}
Let $\hat{p}_{01} = n_{01}/ \left(n_{00} + n_{01}\right)$, $\hat{p}_{10} = n_{10} / \left(n_{10} + n_{11}\right)$, and $S = \hat{p}_{01} + \hat{p}_{10}$. \citet{Brown1977estimation} showed that the maximum likelihood estimate of $\zeta$ exists only when $S < 1$. Under the condition that $S < 1$, the maximum likelihood estimates of $\phi$ and $\zeta$ are given by 
\begin{equation}
\label{eq:MTS_mle}
\hat\phi = \frac{\hat{p}_{01}}{\hat{p}_{01} + \hat{p}_{10}} \qquad \text{and} \qquad
\hat\zeta = \frac{-\hat{p}_{01} \hat{p}_{10} \log(1 - S)}{c S^2}.
\end{equation}
If $S \geq 1$, then the maximum likelihood estimator of $\phi$ is still well-defined and equal to $\hat\phi = \left(n_{01} + n_{11}\right) / K$. 

<<MTS_validity, results='asis'>>=

source("R/Brown Solomon Stevens.R")

proportion_valid <- function(iterations, phi, zeta, K) {
  mu <- phi / zeta
  lambda <- (1 - phi) / zeta

  f <- function(mu, lambda, K) {
    BS <- r_behavior_stream(n = 1, mu = mu, lambda = lambda, 
                            F_event = F_exp(), F_interim = F_exp(), 
                            stream_length = K)
    X <- momentary_time_recording(BS = BS, interval_length = 1, summarize = FALSE)[,1]
    crossprod(cbind(1 - X[1:K], X[1:K]), cbind(1 - X[1 + 1:K], X[1 + 1:K]))
    MTSmle(X, c = 1)
  }
  
  MTS_mle <- data.frame(t(replicate(iterations, f(mu, lambda, K))))
  
  phi_finite <- is.finite(logit(MTS_mle$phi))
  zeta_finite <- is.finite(log(MTS_mle$zeta))
  mean(phi_finite * zeta_finite)
}

phi <- c(0.1, 0.2, 0.3, 0.4, 0.5)
zeta <- c(0.05, 0.1, 0.2, 0.25, 0.4, 0.5)
K <- 60
iterations <- 50

params <- expand.grid(phi = phi, zeta = zeta)
results <- maply(params, proportion_valid, K = K, iterations = iterations)

xtable(results, 
       caption = paste0("Proportion of ",iterations,
                        " Simulated MTS samples (K = ", K,
                        ") in which $0 < \\hat\\phi < 1$ and $0 < \\hat\\zeta < \\infty$."),
       label = "tab:MTS_zeta_valid")
@

The probability that the maximum likelihood estimators are undefined or fall outside of the parameter space is not trivial, even when $K$ is relatively large. Note that in order for the estimates to fall strictly within the parameter space, both a 0-1 transition and a 1-0 transition must be observed, so that $\hat{p}_{01} > 0$, $\hat{p}_{10} > 0$. Table \ref{tab:MTS_zeta_valid} reports the proportion of simulated samples in which both $0 < \hat\phi < 1$ and $0 < \hat\zeta < \infty$, with $K = 60$ and $\zeta$ scaled in terms of the interval length. The estimators remain well-defined with decreasing frequency as incidence increases or prevalence becomes more extreme. The high proportion of samples in which the estimators are undefined is a substantial drawback to this method.

\section{Partial Interval Recording}
\label{sec:PIR}

Now suppose that an observer uses partial interval recording to measure the behavior, using a total of $K$ intervals, each of which has $c$ seconds of active observation time and $d$ seconds of recording time. Let time $t_k = (k-1)(c + d)$ denote the beginning of interval $k$. Let $U_k$ indicate the partial interval record from interval $k$, corresponding to the time from $t_k$ to $t_k + c$, so that $U_k = 1$ if is the behavior occurs at any point during the interval and $U_k = 0$ if the behavior does not occur at all during that interval. Note that $Y(t_k) = 1$ implies that $U_k = 1$ with certainty, while $\Pr\left(U_k = 1\left| Y(t_k) = 0\right.\right) = 1 - \exp\left[ -\zeta c / (1 - \phi)\right]$.

Let $\psi_k$ denote the probability than an event is occurring at time $t_k = (k-1)(c + d)$, given the partial interval record up to that time, 
\begin{equation}
\psi_k = \Pr\left[Y(t_k) = 1 \left| U_1,...,U_{k-1}\right.\right]
\end{equation}
for $k = 2,...,K$ (for ease of notation, set $\psi_1 = \phi$). It follows from (\ref{eq:Markov}) that 
\begin{align*}
\Pr\left(U_k = 1 \left| U_1,...,U_{k-1}\right.\right) &= \psi_k \Pr\left(U_k = 1 \left| Y(t_k) = 1)\right.\right)  + (1 - \psi_k)\Pr\left(U_k = 1 \left| Y(t_k) = 0)\right.\right) \\
&= 1 - (1 - \psi_k)\exp\left( \frac{-\zeta c}{1 - \phi}\right).
\end{align*}
The joint distribution of $U_1,...,U_K$ can then be expressed as 
\begin{align}
\Pr\left(U_1=u_1,...,U_K = u_K\right) &= \Pr\left(U_1=u_1\right) \prod_{k=2}^K \Pr\left(U_k=u_k \left| U_1,...,U_{k-1}\right.\right) \nonumber \\
&= \prod_{k=1}^K \left[1 - (1 - \psi_k)\exp\left( \frac{-\zeta c}{1 - \phi}\right) \right]^{u_k} \left[(1 - \psi_k)\exp\left( \frac{-\zeta c}{1 - \phi}\right)\right]^{(1 - u_k)}.
\end{align}
The log-likelihood of $\phi, \zeta$ is therefore 
\begin{align}
\label{eq:log_lik}
l\left(\phi,\zeta\right) = \sum_{k=1}^K & u_k \ln\left[1 - (1 - \psi_k)\exp\left( \frac{-\zeta c}{1 - \phi}\right)\right]  + (1 - u_k)\left[\ln\left(1 - \psi_k \right) - \frac{\zeta c}{1 - \phi}\right].
\end{align}

It remains to find $\psi_2,...,\psi_K$. Note that $U_{k-1} = 0$ implies that $Y(t_k + c) = 0$, from which it follows that \[
\Pr\left(Y(t_k) = 1 \left| U_1 = u_1,...,U_{k-2} = u_{k-2}, U_{k-1} = 0 \right.\right) = \Pr\left(Y(t_k) = 1 \left|Y(t_{k-1} + c) = 0 \right.\right) = p_0(d). \]
Next, observe that \[
\Pr\left(Y(t_k) = 1, U_{k-1} = 1 \left| Y(t_{k-1}) = 1 \right.\right) = \Pr\left(Y(t_k) = 1 \left| Y(t_{k-1}) = 1 \right.\right) = p_1(c + d) \]
and \begin{align*}
\Pr\left(Y(t_k) = 1, U_{k-1} = 1 \left| Y(t_{k-1}) = 0 \right.\right) &= \int_0^c p_1(c - t) \frac{ \zeta \exp(-t \zeta / (1 - \phi))}{(1 - \phi)} dt \\
& = \phi \left[ 1 - \exp\left(\frac{- \zeta (c + d)}{\phi(1 - \phi)}\right) - \exp\left(\frac{- \zeta c}{1 - \phi}\right) + \exp\left(\frac{- \zeta (\phi c + d)}{\phi(1 - \phi)}\right)\right] \\
&= p_0(c + d) - p_0(d) \exp\left(\frac{- \zeta c}{1 - \phi}\right)
\end{align*}
It follows that \begin{align*}
\Pr\left(Y(t_k) = 1, U_{k-1} = 1 \left| U_1,...,U_{k-2}\right.\right) &= \psi_{k-1} p_1(c + d) + (1 - \psi_{k-1}) \left[p_0(c + d) - p_0(d) \exp\left(\frac{- \zeta c}{1 - \phi}\right)\right] \\
\Pr\left(Y(t_k) = 1 \left| U_1 = u_1,...,U_{k-2} = u_{k-2}, U_{k-1} = 1 \right.\right) &= \frac{\psi_{k-1} p_1(c + d) + (1 - \psi_{k-1}) \left[p_0(c + d) - p_0(d) \exp\left(\frac{- \zeta c}{1 - \phi}\right)\right]}{1 - (1 - \psi_k)\exp\left( \frac{-\zeta c}{1 - \phi}\right)}.
\end{align*}
Thus, $\psi_k$ can be written as a function of $\psi_{k-1}$ and $u_{k-1}$:
\begin{equation}
\psi_k = \left[\frac{\psi_{k-1} p_1(c + d) + (1 - \psi_{k-1}) \left[p_0(c + d) - p_0(d) \exp\left(\frac{- \zeta c}{1 - \phi}\right)\right]}{1 - (1 - \psi_{k-1})\exp\left( \frac{-\zeta c}{1 - \phi}\right)}\right]^{u_{k-1}} \left[p_0(d)\right]^{(1 - u_{k-1})}.
\end{equation}

\section{Whole Interval Recording}
\label{sec:WIR}

\section{Application}
\label{sec:application}

\section{Discussion}
\label{sec:discussion}

\bibliographystyle{apacite}
\bibliography{\bibfile}
 
\end{document}