---
title: "MTS Preliminary Simulation Results"
author: "Daniel M. Swan"
date: "Tuesday, March 03, 2015"
output: pdf_document
---
```{r setup, echo = FALSE}
library(knitr)
opts_chunk$set(echo=FALSE, warning=FALSE)
library(plyr)
library(reshape2)
```

```{r munge}
load("Sim4MTScombined.Rdata")

stats <- c("phi", "logit phi", "zeta", "log zeta")

results_sub <- subset(results, stat %in% stats)

results_sub$MCerror <- results_sub$var / 5000
results_sub$MLE <- with(results_sub, ifelse(theta==Inf & k_priors==1, "MLE",
                                            ifelse(theta==Inf | k_priors==1, "MPLE" ,"PLE")))

MC_error <- dcast(results_sub, stat + MLE ~ K_intervals, 
                  fun.aggregate = max, value.var = "MCerror")


# median/max absolute bias
# median/max RMSE across phi/zeta, for a given level of K, by priors

results_sub$RMSE <- with(results_sub, sqrt(var + bias^2))

summarized <- ddply(results_sub, .(K_intervals, k_priors, theta, stat), summarize,
                      max_bias = max(abs(bias)), median_bias = median(abs(bias)),
                      max_rmse = max(RMSE), median_rmse = median(RMSE))

max_bias <- dcast(summarized, stat + K_intervals + k_priors ~ theta, 
                  value.var = "max_bias")
median_bias <- dcast(summarized, stat + K_intervals + k_priors ~ theta, 
                     value.var = "median_bias")
max_rmse <- dcast(summarized, stat + K_intervals + k_priors ~ theta, 
                  value.var = "max_rmse")
median_rmse <- dcast(summarized, stat + K_intervals + k_priors ~ theta, 
                     value.var = "median_rmse")
```

This document provides a summary of the preliminary simulation of the momentary time sampling (MTS) estimator using both the regular and the penalized log likelihood function. I will summarize the results of the simulation by characterizing:

* The Monte Carlo error for phi and zeta in both their natural parameterizations and the logit of phi and log of zeta
* The error in the estimates of logit phi in terms of the median and maximum bias and RMSE
* The error in the estimates of log zeta in terms of the median and maximum bisa and RMSE

#Monte Carlo error

```{r}
print(MC_error, digits = 3)
```
The maximum Monte Carlo error is quite small in all cases except for zeta in the unpenalized estimates for the natural parameterization of zeta are highly unstable. Given these results, the sample sizes chosen are sufficient in all cases but zeta. In the case of zeta the magnitude of the bias and the fact that unpenalized MTS estimator sometimes produces very large or infinite estimates of zeta, it may be that there is no reasonable sample size large enough to provide adequately small Monte Carlo error.

\newpage

# Logit phi results

## Median bias

```{r}
subset(median_bias, stat=="logit phi", select = -stat)
```
The median absolute bias for logit phi suggests that, on average, the estimator performs worse when the penalized log likelihood is used. For both values of K, larger values for the scale parameter increase the median absolute bias.  When K = 30, increasing the value of the shape parameter slightly decreases the median absolute bias of the estimates. However, the median bias when K = 30 is simply too large for the estimates to be trusted. The bias changes considerably when K = 90. The median absolute bias for the unpenalized estimates is 2.7% and the bias of the penalized estimates range from approximately 3.4% to 5%, with the best estimates at shape = 1.10 and scale = 10. Increasing values for shape may have an impact on the estimates, but the impact does not appear to be uniformly better or worse. Given the very small magnitude, the differences might simply be attributed to Monte Carlo error.

## Maximum bias

```{r}
subset(max_bias, stat=="logit phi", select = -stat)
```
The maximum absolute bias is slightly different. At the absolute worst, the unpenalized MTS estimates are considerably more biased than the penalized estimates. In all cases, the absolute maximum bias is quite large. Increasing the value of K decreases the maximum absolute bias. Unlike with the median bias, at both levels of K increasing the shape parameter reduces the maximum absolute bias. As with the median absolute bias, increasing the values of the scale parameter increases the maximum absolute bias at both levels of K.

\newpage

## Median RMSE
```{r}
subset(median_rmse, stat=="logit phi", select = -stat)
```
In terms of the median RMSE, when K = 30 the unpenalized estimates perform worse than the penalized estimates. Increasing values of the shape parameter slightly decrease the median RMSE, and increasing values of the scale parameter slightly increase the median RMSE. However when K = 90, the median RMSE is fairly stable across all both the unpenalized estimates and the penalized estimates across all levels of the priors.

## Maximum RMSE
```{r}
subset(max_rmse, stat=="logit phi", select = -stat)
````
In terms of the maximum RMSE, the unpenalized estimates perform worse than the penalized estimates at both levels of K. Much like with the median RMSE,  increasing values of the shape parameter slightly decrease the median RMSE, and increasing values of the scale parameter slightly increase the median RMSE. The differences in magnitude may be indicative of a practical difference.

Taken together, this suggests that the estimator may produce approximately unbiased estimates in some cases, the estimates of prevalence are not approximately unbiased across the entire parameter space whether the unpenalized log likelihood or the penalized log likelihood with any of the tested combinations of priors are used.

\newpage

# Log zeta resuts

## Median bias
```{r}
subset(median_bias, stat=="log zeta", select = -stat)
```
The median absolute bias for log zeta suggests that, on average, the estimator performs considerably better when the penalized log likelihood is used. When K = 30, values for the median absolute bias are once again too large for the estimates to be trusted. As with logit phi, increasing the value of the scale parameter increases the median absolute bias at both levels of K. However, unlike logit phi, increase the value of the shape parameter increases the median absolute bias across both levels of K. When K = 90, the absolute bias might be considered adequate at approximately 5.3% when the shape parameter = 1.01 and the scale parameter = 10, but otherwise the median absolute bias is probably too large for the estimates to be considered approximately unbiased.

## Maximum bias

```{r}
subset(max_bias, stat=="log zeta", select = -stat)
```
The maximum absolute bias is somewhat different. When K = 30, the the maximum absolute bias of the unpenalized estimates is considerably larger than the penalized estimates. However, when K = 90, the maximum absolute bias for the unpenalized estimates are better than the penalized ones, although only to a moderate degree. As with the median absolute bias, at both levels of K, increasing the shape parameter and the scale parameter increases the maximum absolute bias.

\newpage

## Median RMSE

```{r}
subset(median_rmse, stat=="log zeta", select = -stat)
```
The median RMSE for log zeta is somewhat analogous to the median RMSE for logit phi. When K = 30, the unpenalized estimates perform worse than the penalized estimates. Increasing the shape parameter and the scale parameter increases the median RMSE. When K = 90, the unpenalized estimates perform worse than the penalized estimates, however the median RMSE is relatively stable across all the levels of the priors.

## Maximum RMSE

```{r}
subset(max_rmse, stat=="log zeta", select = -stat)
```
The maximum RMSE for log zeta is approximately the same as median absolute bias. Increasing the value K decreases the maximum RMSE The unpenalized estimates perform worse than the penalized estimates at both levels of K. Increasing the shape parameter and the scale parameter both increase the maximum RMSE.

Taken together, this suggests that approximately unbiased estimates of zeta might be produced when the penalized log likelihood is used with shape = 1.01 and scale = 10, however unbiased estimates are not produced across the entire parameter space of phi and zeta.

#Further investigation

These results suggest two possible directions for more investigation via simulation. It definitely seems as though it would be valuable to investage smaller values for the scale parameter, given that the smaller of the two tested scale values produced better estimates of both phi and zeta. It also might be worth examining the odd relationship between logit phi's median bias the varying levels of the shape parameter when K = 90. However, given the RMSE when K = 90, it's possible that the error for phi is on average relatively stable at larger values of K.